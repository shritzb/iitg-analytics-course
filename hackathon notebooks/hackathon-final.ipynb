{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12105345,"sourceType":"datasetVersion","datasetId":7621160}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:55:11.045751Z","iopub.execute_input":"2025-06-10T17:55:11.046098Z","iopub.status.idle":"2025-06-10T17:55:13.332555Z","shell.execute_reply.started":"2025-06-10T17:55:11.046063Z","shell.execute_reply":"2025-06-10T17:55:13.331614Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hackathon-set/hacktest.csv\n/kaggle/input/hackathon-set/hacktrain.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"##  STEP 1: Preprocessing – Clean & Smooth NDVI Time Series","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.signal import savgol_filter\n\n# Load datasets\ntrain = pd.read_csv(\"/kaggle/input/hackathon-set/hacktrain.csv\").drop(columns=['Unnamed: 0'])\ntest = pd.read_csv(\"/kaggle/input/hackathon-set/hacktest.csv\").drop(columns=['Unnamed: 0'])\n\n# Identify NDVI columns\nndvi_cols = [col for col in train.columns if '_N' in col]\nndvi_cols.sort()  # Ensure chronological order\n\n# Interpolate and apply Savitzky-Golay smoothing\ndef clean_ndvi(df, is_train=True):\n    df_clean = df.copy()\n    \n    # Interpolation (linear along time)\n    df_clean[ndvi_cols] = df_clean[ndvi_cols].interpolate(method='linear', axis=1, limit_direction='both')\n    \n    # Smoothing\n    window = 7 if len(ndvi_cols) >= 7 else len(ndvi_cols) // 2 * 2 + 1\n    for idx in df_clean.index:\n        try:\n            smoothed = savgol_filter(df_clean.loc[idx, ndvi_cols], window_length=window, polyorder=2)\n            df_clean.loc[idx, ndvi_cols] = smoothed\n        except:\n            pass\n    \n    if is_train:\n        return df_clean[ndvi_cols], df_clean['class']\n    else:\n        return df_clean[['ID'] + ndvi_cols]\n\nX_train, y_train = clean_ndvi(train, is_train=True)\nX_test = clean_ndvi(test, is_train=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:56:28.598826Z","iopub.execute_input":"2025-06-10T17:56:28.599183Z","iopub.status.idle":"2025-06-10T17:57:34.350566Z","shell.execute_reply.started":"2025-06-10T17:56:28.599158Z","shell.execute_reply":"2025-06-10T17:57:34.349746Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## STEP 2: Feature Engineering","metadata":{}},{"cell_type":"code","source":"from scipy.stats import skew, kurtosis\n\ndef extract_features(df):\n    features = pd.DataFrame()\n    ndvi_data = df[ndvi_cols]\n\n    features[\"mean\"] = ndvi_data.mean(axis=1)\n    features[\"std\"] = ndvi_data.std(axis=1)\n    features[\"min\"] = ndvi_data.min(axis=1)\n    features[\"max\"] = ndvi_data.max(axis=1)\n    features[\"skew\"] = ndvi_data.apply(skew, axis=1)\n    features[\"kurtosis\"] = ndvi_data.apply(kurtosis, axis=1)\n    features[\"trend\"] = ndvi_data.apply(lambda row: np.polyfit(range(len(row)), row, 1)[0], axis=1)  # slope\n\n    return features\n\nX_train_feat = extract_features(X_train)\nX_test_feat = extract_features(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:58:30.689568Z","iopub.execute_input":"2025-06-10T17:58:30.689905Z","iopub.status.idle":"2025-06-10T17:58:45.716835Z","shell.execute_reply.started":"2025-06-10T17:58:30.689861Z","shell.execute_reply":"2025-06-10T17:58:45.716022Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## STEP 3: Model Training — Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# Encode target\ny_train_encoded = y_train.astype('category').cat.codes\nlabel_mapping = dict(enumerate(y_train.astype('category').cat.categories))\n\n# Pipeline: Scale + Model\npipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"clf\", LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000))\n])\n\n# Cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(pipeline, X_train_feat, y_train_encoded, cv=cv, scoring='accuracy')\nprint(\"Cross-validated Accuracy:\", scores.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T17:59:18.868052Z","iopub.execute_input":"2025-06-10T17:59:18.868380Z","iopub.status.idle":"2025-06-10T17:59:21.890259Z","shell.execute_reply.started":"2025-06-10T17:59:18.868355Z","shell.execute_reply":"2025-06-10T17:59:21.888762Z"}},"outputs":[{"name":"stdout","text":"Cross-validated Accuracy: 0.8317500000000001\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## STEP 4: Train Final Model & Predict on Test Set","metadata":{}},{"cell_type":"code","source":"# Train on full data\npipeline.fit(X_train_feat, y_train_encoded)\n\n# Predict\ntest_preds = pipeline.predict(X_test_feat)\ntest_labels = [label_mapping[i] for i in test_preds]\n\n# Create submission\nsubmission = pd.DataFrame({\n    \"ID\": X_test[\"ID\"],\n    \"class\": test_labels\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T18:00:14.809774Z","iopub.execute_input":"2025-06-10T18:00:14.810125Z","iopub.status.idle":"2025-06-10T18:00:15.518197Z","shell.execute_reply.started":"2025-06-10T18:00:14.810101Z","shell.execute_reply":"2025-06-10T18:00:15.516381Z"}},"outputs":[{"name":"stdout","text":"Submission file saved!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T18:00:23.752542Z","iopub.execute_input":"2025-06-10T18:00:23.752901Z","iopub.status.idle":"2025-06-10T18:00:23.774425Z","shell.execute_reply.started":"2025-06-10T18:00:23.752878Z","shell.execute_reply":"2025-06-10T18:00:23.773471Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        ID   class\n0        1  forest\n1        2  forest\n2        3  forest\n3        4  forest\n4        5  forest\n...    ...     ...\n2840  2841   water\n2841  2842   water\n2842  2843   water\n2843  2844   water\n2844  2845   water\n\n[2845 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>forest</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2840</th>\n      <td>2841</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <th>2841</th>\n      <td>2842</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <th>2842</th>\n      <td>2843</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <th>2843</th>\n      <td>2844</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <th>2844</th>\n      <td>2845</td>\n      <td>water</td>\n    </tr>\n  </tbody>\n</table>\n<p>2845 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}